{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import requests\n",
        "import time\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "7jvVV6PrhFf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cx2LSaDg94a",
        "outputId": "03f6d880-bef3-4472-e61a-09c71eb01c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/detr/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 108MB/s]\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth\" to /root/.cache/torch/hub/checkpoints/detr-r50-e632da11.pth\n",
            "100%|██████████| 159M/159M [00:01<00:00, 132MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " → <class 'models.detr.DETR'>\n",
            "transformer → <class 'models.transformer.Transformer'>\n",
            "transformer.encoder → <class 'models.transformer.TransformerEncoder'>\n",
            "transformer.encoder.layers → <class 'torch.nn.modules.container.ModuleList'>\n",
            "transformer.encoder.layers.0 → <class 'models.transformer.TransformerEncoderLayer'>\n",
            "transformer.encoder.layers.0.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.encoder.layers.0.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.encoder.layers.0.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.0.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.0.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.0.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.0.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.0.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.0.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.1 → <class 'models.transformer.TransformerEncoderLayer'>\n",
            "transformer.encoder.layers.1.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.encoder.layers.1.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.encoder.layers.1.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.1.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.1.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.1.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.1.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.1.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.1.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.2 → <class 'models.transformer.TransformerEncoderLayer'>\n",
            "transformer.encoder.layers.2.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.encoder.layers.2.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.encoder.layers.2.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.2.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.2.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.2.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.2.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.2.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.2.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.3 → <class 'models.transformer.TransformerEncoderLayer'>\n",
            "transformer.encoder.layers.3.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.encoder.layers.3.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.encoder.layers.3.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.3.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.3.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.3.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.3.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.3.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.3.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.4 → <class 'models.transformer.TransformerEncoderLayer'>\n",
            "transformer.encoder.layers.4.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.encoder.layers.4.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.encoder.layers.4.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.4.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.4.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.4.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.4.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.4.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.4.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.5 → <class 'models.transformer.TransformerEncoderLayer'>\n",
            "transformer.encoder.layers.5.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.encoder.layers.5.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.encoder.layers.5.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.5.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.5.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.encoder.layers.5.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.5.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.encoder.layers.5.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.encoder.layers.5.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder → <class 'models.transformer.TransformerDecoder'>\n",
            "transformer.decoder.layers → <class 'torch.nn.modules.container.ModuleList'>\n",
            "transformer.decoder.layers.0 → <class 'models.transformer.TransformerDecoderLayer'>\n",
            "transformer.decoder.layers.0.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.0.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.0.multihead_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.0.multihead_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.0.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.0.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.0.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.0.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.0.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.0.norm3 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.0.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.0.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.0.dropout3 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.1 → <class 'models.transformer.TransformerDecoderLayer'>\n",
            "transformer.decoder.layers.1.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.1.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.1.multihead_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.1.multihead_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.1.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.1.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.1.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.1.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.1.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.1.norm3 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.1.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.1.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.1.dropout3 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.2 → <class 'models.transformer.TransformerDecoderLayer'>\n",
            "transformer.decoder.layers.2.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.2.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.2.multihead_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.2.multihead_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.2.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.2.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.2.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.2.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.2.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.2.norm3 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.2.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.2.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.2.dropout3 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.3 → <class 'models.transformer.TransformerDecoderLayer'>\n",
            "transformer.decoder.layers.3.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.3.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.3.multihead_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.3.multihead_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.3.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.3.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.3.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.3.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.3.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.3.norm3 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.3.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.3.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.3.dropout3 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.4 → <class 'models.transformer.TransformerDecoderLayer'>\n",
            "transformer.decoder.layers.4.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.4.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.4.multihead_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.4.multihead_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.4.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.4.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.4.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.4.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.4.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.4.norm3 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.4.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.4.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.4.dropout3 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.5 → <class 'models.transformer.TransformerDecoderLayer'>\n",
            "transformer.decoder.layers.5.self_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.5.self_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.5.multihead_attn → <class 'torch.nn.modules.activation.MultiheadAttention'>\n",
            "transformer.decoder.layers.5.multihead_attn.out_proj → <class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
            "transformer.decoder.layers.5.linear1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.5.dropout → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.5.linear2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "transformer.decoder.layers.5.norm1 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.5.norm2 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.5.norm3 → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "transformer.decoder.layers.5.dropout1 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.5.dropout2 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.layers.5.dropout3 → <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.decoder.norm → <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "class_embed → <class 'torch.nn.modules.linear.Linear'>\n",
            "bbox_embed → <class 'models.detr.MLP'>\n",
            "bbox_embed.layers → <class 'torch.nn.modules.container.ModuleList'>\n",
            "bbox_embed.layers.0 → <class 'torch.nn.modules.linear.Linear'>\n",
            "bbox_embed.layers.1 → <class 'torch.nn.modules.linear.Linear'>\n",
            "bbox_embed.layers.2 → <class 'torch.nn.modules.linear.Linear'>\n",
            "query_embed → <class 'torch.nn.modules.sparse.Embedding'>\n",
            "input_proj → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone → <class 'models.backbone.Joiner'>\n",
            "backbone.0 → <class 'models.backbone.Backbone'>\n",
            "backbone.0.body → <class 'torchvision.models._utils.IntermediateLayerGetter'>\n",
            "backbone.0.body.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.maxpool → <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
            "backbone.0.body.layer1 → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer1.0 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer1.0.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.0.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.0.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.0.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.0.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.0.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.0.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer1.0.downsample → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer1.0.downsample.0 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.0.downsample.1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.1 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer1.1.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.1.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.1.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.1.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.1.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.1.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.1.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer1.2 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer1.2.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.2.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.2.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.2.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.2.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer1.2.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer1.2.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer2 → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer2.0 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer2.0.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.0.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.0.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.0.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.0.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.0.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.0.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer2.0.downsample → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer2.0.downsample.0 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.0.downsample.1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.1 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer2.1.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.1.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.1.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.1.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.1.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.1.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.1.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer2.2 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer2.2.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.2.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.2.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.2.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.2.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.2.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.2.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer2.3 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer2.3.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.3.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.3.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.3.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.3.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer2.3.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer2.3.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer3 → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer3.0 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer3.0.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.0.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.0.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.0.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.0.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.0.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.0.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer3.0.downsample → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer3.0.downsample.0 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.0.downsample.1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.1 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer3.1.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.1.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.1.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.1.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.1.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.1.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.1.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer3.2 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer3.2.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.2.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.2.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.2.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.2.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.2.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.2.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer3.3 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer3.3.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.3.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.3.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.3.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.3.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.3.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.3.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer3.4 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer3.4.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.4.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.4.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.4.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.4.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.4.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.4.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer3.5 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer3.5.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.5.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.5.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.5.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.5.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer3.5.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer3.5.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer4 → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer4.0 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer4.0.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.0.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.0.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.0.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.0.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.0.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.0.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer4.0.downsample → <class 'torch.nn.modules.container.Sequential'>\n",
            "backbone.0.body.layer4.0.downsample.0 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.0.downsample.1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.1 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer4.1.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.1.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.1.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.1.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.1.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.1.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.1.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.0.body.layer4.2 → <class 'torchvision.models.resnet.Bottleneck'>\n",
            "backbone.0.body.layer4.2.conv1 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.2.bn1 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.2.conv2 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.2.bn2 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.2.conv3 → <class 'torch.nn.modules.conv.Conv2d'>\n",
            "backbone.0.body.layer4.2.bn3 → <class 'models.backbone.FrozenBatchNorm2d'>\n",
            "backbone.0.body.layer4.2.relu → <class 'torch.nn.modules.activation.ReLU'>\n",
            "backbone.1 → <class 'models.position_encoding.PositionEmbeddingSine'>\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Print all named modules\n",
        "for name, module in model.named_modules():\n",
        "    print(name, '→', type(module))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load image from Google Drive\n",
        "image_path = '/content/drive/MyDrive/peddet_2_1.jpg'\n",
        "image = Image.open(image_path).convert('RGB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae25KYiBheFq",
        "outputId": "945079c3-47d2-4202-824d-26c1e35f71de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure total model inference time (GPU)\n",
        "start_event = torch.cuda.Event(enable_timing=True)\n",
        "end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.cuda.synchronize()  # Make sure GPU is ready\n",
        "    start_event.record()\n",
        "\n",
        "    outputs = model(img_tensor)  # Full forward pass\n",
        "\n",
        "    end_event.record()\n",
        "    torch.cuda.synchronize()  # Wait for all ops to finish\n",
        "\n",
        "total_model_time = start_event.elapsed_time(end_event) / 1000.0  # in seconds\n",
        "print(f\"\\n✅ Total model inference time (end-to-end): {total_model_time:.6f} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hInyHaSMnzg7",
        "outputId": "9fcad663-985a-4222-f910-1d4156da8a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Total model inference time (end-to-end): 0.158241 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "# Image + model loading (as before)\n",
        "image = Image.open(\"/content/drive/MyDrive/peddet_2_1.jpg\").convert(\"RGB\")\n",
        "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
        "model.eval().cuda()\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize(800),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "img_tensor = transform(image).unsqueeze(0).cuda()\n",
        "\n",
        "# Warm-up\n",
        "with torch.no_grad():\n",
        "    for _ in range(5):\n",
        "        _ = model(img_tensor)\n",
        "\n",
        "# Accurate profiling with PyTorch Profiler\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "    record_shapes=True,\n",
        "    with_stack=True,\n",
        "    profile_memory=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        with record_function(\"model_inference\"):\n",
        "            _ = model(img_tensor)\n",
        "\n",
        "# Print high-level summary\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=15))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InRDVclKoZ6M",
        "outputId": "802712d4-63a5-47d8-dc9e-bfd1d5ba7b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_detr_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      96.199ms       103.60%      96.199ms      96.199ms           0 b           0 b           0 b           0 b             1  \n",
            "                                        model_inference        24.28%      24.904ms        60.67%      62.233ms      62.233ms       0.000us         0.00%      92.854ms      92.854ms           0 b           0 b     225.50 Kb      -3.68 Gb             1  \n",
            "                                           aten::conv2d         0.23%     238.381us         4.82%       4.949ms      91.650us       0.000us         0.00%      35.808ms     663.115us           0 b           0 b     976.43 Mb           0 b            54  \n",
            "                                      aten::convolution         0.33%     336.121us         4.59%       4.711ms      87.236us       0.000us         0.00%      35.808ms     663.115us           0 b           0 b     976.43 Mb           0 b            54  \n",
            "                                     aten::_convolution         0.41%     422.996us         4.26%       4.375ms      81.011us       0.000us         0.00%      35.808ms     663.115us           0 b           0 b     976.43 Mb           0 b            54  \n",
            "                                aten::cudnn_convolution         2.19%       2.247ms         3.83%       3.927ms      72.713us      35.800ms        38.56%      35.800ms     662.964us           0 b           0 b     976.43 Mb     976.43 Mb            54  \n",
            "                                  volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us      15.060ms        16.22%      15.060ms     502.003us           0 b           0 b           0 b           0 b            30  \n",
            "_5x_cudnn_volta_scudnn_winograd_128x128_ldg1_ldg4_re...         0.00%       0.000us         0.00%       0.000us       0.000us      10.180ms        10.96%      10.180ms     783.087us           0 b           0 b           0 b           0 b            13  \n",
            "                                              aten::add         2.41%       2.471ms         3.67%       3.764ms      23.233us       9.003ms         9.70%       9.003ms      55.573us           0 b           0 b    1001.52 Mb    1001.52 Mb           162  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       8.906ms         9.59%       8.906ms     129.067us           0 b           0 b           0 b           0 b            69  \n",
            "                                              aten::mul         2.04%       2.097ms         3.22%       3.300ms      18.333us       8.682ms         9.35%       8.682ms      48.236us           0 b           0 b     985.98 Mb     985.98 Mb           180  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       8.600ms         9.26%       8.600ms     145.765us           0 b           0 b           0 b           0 b            59  \n",
            "                                          aten::softmax         0.05%      53.828us         0.55%     563.214us      31.290us       0.000us         0.00%       8.425ms     468.060us           0 b           0 b     254.18 Mb           0 b            18  \n",
            "                                         aten::_softmax         0.38%     385.094us         0.50%     509.386us      28.299us       8.425ms         9.07%       8.425ms     468.060us           0 b           0 b     254.18 Mb     254.18 Mb            18  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       8.401ms         9.05%       8.401ms     158.510us           0 b           0 b           0 b           0 b            53  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 102.578ms\n",
            "Self CUDA time total: 92.854ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# ✅ Load image\n",
        "image = Image.open(\"/content/drive/MyDrive/peddet_2_1.jpg\").convert(\"RGB\")\n",
        "\n",
        "# ✅ Load model and move to GPU\n",
        "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
        "model.eval().cuda()\n",
        "\n",
        "# ✅ Preprocess image\n",
        "transform = T.Compose([\n",
        "    T.Resize(800),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "img_tensor = transform(image).unsqueeze(0).cuda()\n",
        "\n",
        "# ✅ Warm-up pass (important for GPU)\n",
        "with torch.no_grad():\n",
        "    for _ in range(5):\n",
        "        _ = model(img_tensor)\n",
        "\n",
        "# ✅ Measure actual inference time\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _ = model(img_tensor)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "end = time.time()\n",
        "\n",
        "# ✅ Print result\n",
        "print(f\"\\n⏱️ Actual GPU inference time (wall clock): {end - start:.6f} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4tSgvWzpPpg",
        "outputId": "bd3650fa-710c-4eec-e63c-9a8e20b5de71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_detr_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏱️ Actual GPU inference time (wall clock): 0.096108 sec\n"
          ]
        }
      ]
    }
  ]
}